{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 20:27:40 INFO: Loading these models for language: uk (Ukrainian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | iu      |\n",
      "| mwt       | iu      |\n",
      "| pos       | iu      |\n",
      "| lemma     | iu      |\n",
      "| depparse  | iu      |\n",
      "=======================\n",
      "\n",
      "2020-04-25 20:27:40 INFO: Use device: cpu\n",
      "2020-04-25 20:27:40 INFO: Loading: tokenize\n",
      "2020-04-25 20:27:40 INFO: Loading: mwt\n",
      "2020-04-25 20:27:40 INFO: Loading: pos\n",
      "2020-04-25 20:27:41 INFO: Loading: lemma\n",
      "2020-04-25 20:27:41 INFO: Loading: depparse\n",
      "2020-04-25 20:27:42 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import stanza\n",
    "from spacy_stanza import StanzaLanguage\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "\n",
    "snlp = stanza.Pipeline(lang=\"uk\")\n",
    "nlp = StanzaLanguage(snlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prettifier(texts, site):\n",
    "    prettified = []\n",
    "    for paragraphs in texts:\n",
    "        if site == 'kunsht':\n",
    "            pretty_text = ' '.join([p.replace('\\xa0', ' ') for p in paragraphs[:-8] if len(p)>1])\n",
    "        elif (site == 'nihilist' or site == 'was') and len(paragraphs) > 3:\n",
    "            pretty_text = ' '.join([p.replace('\\xa0', ' ') for p in paragraphs[:-1] if len(p.split(' '))>3])\n",
    "        elif site == 'lb' and len(paragraphs) > 3:\n",
    "            pretty_text = ' '.join([p.replace('\\xa0', ' ') for p in paragraphs if len(p.split(' '))>3])\n",
    "        else:\n",
    "            print ('wring site keyword')\n",
    "            return\n",
    "        prettified.append(pretty_text)\n",
    "    return prettified\n",
    "\n",
    "def paragraph_prettifier(texts, site):\n",
    "    prettified_paragraphs = []\n",
    "    if site == 'kunsht':\n",
    "        p_slice = slice(-8)\n",
    "    elif site == 'was' or site == 'nihilist':\n",
    "        p_slice =slice(-1)\n",
    "    elif site in ('lb_blogs', 'lb_news'):\n",
    "        p_slice = slice(None,None)\n",
    "    for paragraphs in texts:\n",
    "        for p in paragraphs[p_slice]:\n",
    "            if len(p) > 3 and len(p.split(' '))>5 and not p.isspace(): \n",
    "                    prettified_paragraphs.append(p)\n",
    "    return prettified_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    'kunsht': joblib.load('kunsht.joblib'), \n",
    "    'nihilist': joblib.load('nihilist.joblib'), \n",
    "    'lb_blogs': joblib.load('lb_100_pages.joblib'), \n",
    "    'was': joblib.load('was_texts.joblib'),\n",
    "    'lb_news': joblib.load('lb_politycs_news_for_100_pages.joblib'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts before processing\n",
      "kunsht 177 4915\n",
      "Number of texts before processing\n",
      "nihilist 241 4146\n",
      "Number of texts before processing\n",
      "lb_blogs 1786 28809\n",
      "Number of texts before processing\n",
      "was 448 10257\n",
      "Number of texts before processing\n",
      "lb_news 2195 17492\n"
     ]
    }
   ],
   "source": [
    "paragraphs_data = {}\n",
    "\n",
    "for site, data in raw_data.items():\n",
    "    print('Number of texts before processing')\n",
    "    paragraphs_data[site] = paragraph_prettifier(data, site)\n",
    "    print(site, len(data), len(paragraphs_data[site]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447cae64fe464785bf57fe33ec9dc95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68abd33c7c8648cbb053abe6bf773f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a884460cf53a404d88b04100991710ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae89f5411d644aababe805d2d061a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5249a5980664efc8442076b8d612e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#spacy_docs = {}\n",
    "\n",
    "for site, data in paragraphs_data.items():\n",
    "    spacy_docs[site] = list(tqdm(nlp.pipe(data[:750])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_with_spacy(doc):\n",
    "    lemmas = []\n",
    "    text_without_stops = []\n",
    "    poses = []\n",
    "    \n",
    "    doc_tokens = [w.text for w in doc]\n",
    "    for word in doc:\n",
    "        if word not in spacy.lang.uk.stop_words.STOP_WORDS:\n",
    "            text_without_stops.append(word.text)\n",
    "        lemmas.append(word.lemma_)\n",
    "        poses.append(word.pos_)\n",
    "    text_without_propn = [\n",
    "        word if pos != 'PROPN' else pos\n",
    "        for (word, pos)\n",
    "        in zip(doc_tokens, poses)\n",
    "    ]\n",
    "    return text_without_stops, lemmas, poses, text_without_propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "У землі ховається чимало нових відкриттів. Палеонтолог Вадим Яненко знає це як ніхто. Разом із колегою з Швейцарії Давідом Василяном він описав новий вид саламандр – Palaeoproteus miocenicus. Їхні рештки знайшли зокрема в селі Гриців Хмельницької області. Статтю про відкриття вчених опублікували в журналі Nature. Куншт поговорив з Вадимом про методи дослідження викопних решток і те, як опублікувати своє дослідження в одному з найвідоміших наукових журналів."
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = spacy_docs['kunsht'][0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 It's Modeling Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_to_label = {\n",
    "    'kunsht': ('neutral', 'val'),\n",
    "    'nihilist': ('subjective', 'val'), \n",
    "    'lb_blogs': ('subjective', 'train'), \n",
    "    'was': ('neutral', 'val'),\n",
    "    'lb_news': ('neutral', 'train'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added kunsht\n",
      "added nihilist\n",
      "added lb_blogs\n",
      "added was\n",
      "added lb_news\n"
     ]
    }
   ],
   "source": [
    "total_texts = []\n",
    "for site, (label, sample) in site_to_label.items():\n",
    "    for doc in spacy_docs[site]:\n",
    "        text_without_stops, lemmas, poses, text_without_propn = extract_features_with_spacy(doc)\n",
    "        text = doc.text\n",
    "        total_texts += [\n",
    "            (site, \n",
    "             label, \n",
    "             sample, \n",
    "             text, \n",
    "             ' '.join(text_without_stops), \n",
    "             ' '.join(lemmas), \n",
    "             ' '.join(poses), \n",
    "             ' '.join(text_without_propn)) \n",
    "        ]\n",
    "    print(f'added {site}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total_texts, columns=['site', 'label', 'sample', 'text', 'w_stops', 'lemmas', 'poses', 'text_without_propn'])\n",
    "#val_df = pd.DataFrame(validate, columns=['text', 'label', 'w_stops', 'lemmas', 'poses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>sample</th>\n",
       "      <th>text</th>\n",
       "      <th>w_stops</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>poses</th>\n",
       "      <th>text_without_propn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunsht</td>\n",
       "      <td>neutral</td>\n",
       "      <td>val</td>\n",
       "      <td>У землі ховається чимало нових відкриттів. Пал...</td>\n",
       "      <td>У землі ховається чимало нових відкриттів . Па...</td>\n",
       "      <td>у земля ховатися чимало новий відкриття . пале...</td>\n",
       "      <td>ADP NOUN VERB ADV ADJ NOUN PUNCT NOUN PROPN PR...</td>\n",
       "      <td>У землі ховається чимало нових відкриттів . Па...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kunsht</td>\n",
       "      <td>neutral</td>\n",
       "      <td>val</td>\n",
       "      <td>Це була досить цікава історія. Я орнітолог, на...</td>\n",
       "      <td>Це була досить цікава історія . Я орнітолог , ...</td>\n",
       "      <td>це бути досить цікавий історія . я орнітолог ,...</td>\n",
       "      <td>PRON AUX ADV ADJ NOUN PUNCT PRON NOUN PUNCT VE...</td>\n",
       "      <td>Це була досить цікава історія . Я орнітолог , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kunsht</td>\n",
       "      <td>neutral</td>\n",
       "      <td>val</td>\n",
       "      <td>У 2017 році мій колега Олександр Ковальчук поз...</td>\n",
       "      <td>У 2017 році мій колега Олександр Ковальчук поз...</td>\n",
       "      <td>у 2017 рік мій колега Олександр Ковальчук позн...</td>\n",
       "      <td>ADP ADJ NOUN DET NOUN PROPN PROPN VERB PRON AD...</td>\n",
       "      <td>У 2017 році мій колега PROPN PROPN познайомив ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kunsht</td>\n",
       "      <td>neutral</td>\n",
       "      <td>val</td>\n",
       "      <td>Міоцен – найновіша епоха періоду неогену, друг...</td>\n",
       "      <td>Міоцен – найновіша епоха періоду неогену , дру...</td>\n",
       "      <td>міоцен – найновіший епоха період неогена , дру...</td>\n",
       "      <td>NOUN PUNCT ADJ NOUN NOUN NOUN PUNCT ADJ NOUN A...</td>\n",
       "      <td>Міоцен – найновіша епоха періоду неогену , дру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kunsht</td>\n",
       "      <td>neutral</td>\n",
       "      <td>val</td>\n",
       "      <td>Серед земноводних, що жили на території Україн...</td>\n",
       "      <td>Серед земноводних , що жили на території Украї...</td>\n",
       "      <td>серед земноводний , що жити на територія Украї...</td>\n",
       "      <td>ADP ADJ PUNCT SCONJ VERB ADP NOUN PROPN ADP NO...</td>\n",
       "      <td>Серед земноводних , що жили на території PROPN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     site    label sample                                               text  \\\n",
       "0  kunsht  neutral    val  У землі ховається чимало нових відкриттів. Пал...   \n",
       "1  kunsht  neutral    val  Це була досить цікава історія. Я орнітолог, на...   \n",
       "2  kunsht  neutral    val  У 2017 році мій колега Олександр Ковальчук поз...   \n",
       "3  kunsht  neutral    val  Міоцен – найновіша епоха періоду неогену, друг...   \n",
       "4  kunsht  neutral    val  Серед земноводних, що жили на території Україн...   \n",
       "\n",
       "                                             w_stops  \\\n",
       "0  У землі ховається чимало нових відкриттів . Па...   \n",
       "1  Це була досить цікава історія . Я орнітолог , ...   \n",
       "2  У 2017 році мій колега Олександр Ковальчук поз...   \n",
       "3  Міоцен – найновіша епоха періоду неогену , дру...   \n",
       "4  Серед земноводних , що жили на території Украї...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  у земля ховатися чимало новий відкриття . пале...   \n",
       "1  це бути досить цікавий історія . я орнітолог ,...   \n",
       "2  у 2017 рік мій колега Олександр Ковальчук позн...   \n",
       "3  міоцен – найновіший епоха період неогена , дру...   \n",
       "4  серед земноводний , що жити на територія Украї...   \n",
       "\n",
       "                                               poses  \\\n",
       "0  ADP NOUN VERB ADV ADJ NOUN PUNCT NOUN PROPN PR...   \n",
       "1  PRON AUX ADV ADJ NOUN PUNCT PRON NOUN PUNCT VE...   \n",
       "2  ADP ADJ NOUN DET NOUN PROPN PROPN VERB PRON AD...   \n",
       "3  NOUN PUNCT ADJ NOUN NOUN NOUN PUNCT ADJ NOUN A...   \n",
       "4  ADP ADJ PUNCT SCONJ VERB ADP NOUN PROPN ADP NO...   \n",
       "\n",
       "                                  text_without_propn  \n",
       "0  У землі ховається чимало нових відкриттів . Па...  \n",
       "1  Це була досить цікава історія . Я орнітолог , ...  \n",
       "2  У 2017 році мій колега PROPN PROPN познайомив ...  \n",
       "3  Міоцен – найновіша епоха періоду неогену , дру...  \n",
       "4  Серед земноводних , що жили на території PROPN...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 8)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(~df['text'].str.contains('Рудоманов')) |(~df['text'].str.contains('Ð'))].copy()\n",
    "#val_df = val_df[~val_df['text'].str.contains('Ð')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       2250\n",
       "subjective    1500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_try = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(\n",
    "    df[df['sample'] == 'train'][column_to_try],\n",
    "    df[df['sample'] == 'train']['label'],\n",
    "    random_state=42,\n",
    "    test_size=0.10,\n",
    "    stratify=df[df['sample'] == 'train']['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train_dev,\n",
    "    y_train_dev,\n",
    "    random_state=42,\n",
    "    test_size=0.20,\n",
    "    stratify=y_train_dev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df[df['sample']=='val'][column_to_try]\n",
    "y_val = df[df['sample']=='val']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080,) (1080,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subjective    540\n",
       "neutral       540\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.00      0.00      0.00       135\n",
      "  subjective       0.50      1.00      0.67       135\n",
      "\n",
      "    accuracy                           0.50       270\n",
      "   macro avg       0.25      0.50      0.33       270\n",
      "weighted avg       0.25      0.50      0.33       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yevhen/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, ['subjective']*len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, fbeta_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lr_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(\n",
    "        random_state=42, \n",
    "        solver = 'sag',\n",
    "        multi_class='multinomial',\n",
    "        max_iter=6000,\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(\n",
    "        random_state=42, \n",
    "        solver = 'sag',\n",
    "        multi_class='multinomial',\n",
    "        max_iter=6000,\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        random_state=42, \n",
    "        max_depth=10,   \n",
    "        n_estimators=2000,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3120    28 травня 2019 року новий президент Володимир ...\n",
       "3677    Нагадаємо, 20 січня першим заступником директо...\n",
       "1851    Навіщо все так ускладнювати? Давайте розберемось.\n",
       "1530    Проєкт на десяти сторінках. Серед позитиву — у...\n",
       "3373    Всі ці зміни закладені в законопроєкті про реф...\n",
       "                              ...                        \n",
       "3168    Ім'я позивача суд не вказав, але повідомив, що...\n",
       "1666    Проект передбачає доповнення Регламенту новою ...\n",
       "2124    Право власності орендар отримує після першого ...\n",
       "3465    Колишній голова Антитерористичного центру СБУ ...\n",
       "1773    За проектом закону №3208 Товариства власників ...\n",
       "Name: text, Length: 1080, dtype: object"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lr_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN PERFORMANCE\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=6000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.90      0.95      0.92       135\n",
      "  subjective       0.94      0.89      0.92       135\n",
      "\n",
      "    accuracy                           0.92       270\n",
      "   macro avg       0.92      0.92      0.92       270\n",
      "weighted avg       0.92      0.92      0.92       270\n",
      "\n",
      "ROC-AUC score = 0.9636762688614541\n",
      "F-0.5 score = 0.9331259720062206\n",
      "================================================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=6000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.89      0.81      0.85       135\n",
      "  subjective       0.83      0.90      0.86       135\n",
      "\n",
      "    accuracy                           0.86       270\n",
      "   macro avg       0.86      0.86      0.86       270\n",
      "weighted avg       0.86      0.86      0.86       270\n",
      "\n",
      "ROC-AUC score = 0.9423319615912209\n",
      "F-0.5 score = 0.8414464534075102\n",
      "================================================================================\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
      "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.79      0.92      0.85       135\n",
      "  subjective       0.90      0.76      0.83       135\n",
      "\n",
      "    accuracy                           0.84       270\n",
      "   macro avg       0.85      0.84      0.84       270\n",
      "weighted avg       0.85      0.84      0.84       270\n",
      "\n",
      "ROC-AUC score = 0.9119890260631002\n",
      "F-0.5 score = 0.8714043993231813\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN PERFORMANCE')\n",
    "for clf in (count_lr_clf, tf_clf, tf_rf):\n",
    "    y_pred = clf.predict(X_dev)\n",
    "    y_pred_proba = clf.predict_proba(X_dev)[:,1]\n",
    "    f_beta_score = fbeta_score(y_dev, y_pred, beta=0.5, pos_label='subjective')\n",
    "    print(clf['clf'])\n",
    "    print(classification_report(y_dev, y_pred))\n",
    "    print(f'ROC-AUC score = {roc_auc_score(y_dev, y_pred_proba)}')\n",
    "    print(f'F-0.5 score = {f_beta_score}')\n",
    "    print('='*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=6000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.70      0.28      0.40      1500\n",
      "  subjective       0.35      0.76      0.47       750\n",
      "\n",
      "    accuracy                           0.44      2250\n",
      "   macro avg       0.52      0.52      0.44      2250\n",
      "weighted avg       0.58      0.44      0.43      2250\n",
      "\n",
      "ROC-AUC score = 0.5710871111111111\n",
      "F-0.5 score = 0.38761279737489746\n",
      "================================================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=6000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.72      0.26      0.38      1500\n",
      "  subjective       0.35      0.80      0.48       750\n",
      "\n",
      "    accuracy                           0.44      2250\n",
      "   macro avg       0.53      0.53      0.43      2250\n",
      "weighted avg       0.59      0.44      0.41      2250\n",
      "\n",
      "ROC-AUC score = 0.5817386666666666\n",
      "F-0.5 score = 0.392866543827323\n",
      "================================================================================\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
      "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.71      0.37      0.49      1500\n",
      "  subjective       0.36      0.70      0.47       750\n",
      "\n",
      "    accuracy                           0.48      2250\n",
      "   macro avg       0.54      0.54      0.48      2250\n",
      "weighted avg       0.59      0.48      0.48      2250\n",
      "\n",
      "ROC-AUC score = 0.5893395555555556\n",
      "F-0.5 score = 0.3969569147333535\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for clf in (count_lr_clf, tf_clf, tf_rf):\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_pred_proba = clf.predict_proba(X_val)[:,1]\n",
    "    f_beta_score = fbeta_score(y_val, y_pred, beta=0.5, pos_label='subjective')\n",
    "    print(clf['clf'])\n",
    "    print(classification_report(y_val, clf.predict(X_val)))\n",
    "    print(f'ROC-AUC score = {roc_auc_score(y_val, y_pred_proba)}')\n",
    "    print(f'F-0.5 score = {f_beta_score}')\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NGRAM = 2\n",
      "LABEL IS subjective\n",
      "[('те що', 83), ('тому що', 58), ('під час', 51), ('це не', 51), ('може бути', 42), ('не може', 39), ('2019 року', 34), ('не лише', 32), ('не буде', 31), ('так само', 30), ('про те', 30), ('власників землі', 30), ('того що', 27), ('до того', 26), ('відповідно до', 25), ('млрд грн', 25), ('не тільки', 25), ('не було', 24), ('того щоб', 24), ('не має', 23), ('чи не', 22), ('що не', 22), ('2020 року', 21), ('тому числі', 21), ('тих хто', 21), ('таким чином', 20), ('навіть якщо', 20), ('але не', 20), ('зв язку', 20), ('верховної ради', 20), ('що ми', 19), ('ніколи не', 19), ('covid 19', 19), ('ми не', 18), ('все це', 18), ('закону україни', 18), ('має бути', 18), ('але це', 17), ('того як', 17), ('для того', 17)]\n",
      " \n",
      "LABEL IS neutral\n",
      "[('під час', 135), ('те що', 85), ('про це', 79), ('тому що', 76), ('про те', 42), ('не було', 36), ('прим ред', 34), ('що це', 32), ('ðµñ ðµð', 32), ('ð½ð ð¾ð', 32), ('крім того', 31), ('до того', 31), ('того як', 31), ('2019 року', 30), ('тривалість життя', 29), ('ð¾ð ð¾ñ', 28), ('на території', 27), ('років тому', 26), ('але не', 26), ('за допомогою', 26), ('ð¾ñ ð¾ð', 26), ('на початку', 25), ('не лише', 25), ('не тільки', 25), ('володимир зеленський', 25), ('верховної ради', 25), ('після того', 24), ('що вони', 22), ('ð²ð ð²', 22), ('разом із', 21), ('може бути', 21), ('ми не', 21), ('на сайті', 21), ('після цього', 21), ('нагадаємо що', 21), ('так само', 20), ('можна було', 20), ('ð½ð ð²ñ', 20), ('ð¾ð ð¾ð²ñ', 20), ('ð²ð ðµ', 20)]\n",
      " \n",
      " NGRAM = 3\n",
      "LABEL IS subjective\n",
      "[('про те що', 20), ('закону україни про', 15), ('внесення змін до', 13), ('не може бути', 11), ('так само як', 10), ('той же час', 10), ('для того щоб', 10), ('про внесення змін', 10), ('після того як', 9), ('замість того щоб', 9), ('верховної ради україни', 9), ('на відміну від', 8), ('той факт що', 8), ('на те що', 8), ('кримінального кодексу україни', 8), ('ринку електричної енергії', 7), ('товариства власників землі', 7), ('на тимчасово окупованій', 7), ('тимчасово окупованій території', 7), ('якщо припустити що', 6), ('через те що', 6), ('але це не', 6), ('це не означає', 6), ('завдання для волонтерів', 6), ('другої світової війни', 6), ('до того що', 6), ('якщо розглядати його', 5), ('тим більше що', 5), ('попри те що', 5), ('не те що', 5), ('не означає що', 5), ('він не може', 5), ('до того як', 5), ('which side are', 5), ('side are you', 5), ('are you on', 5), ('для тих хто', 5), ('проект закону україни', 5), ('статусі суб єкта', 5), ('суб єкта підвищеного', 5)]\n",
      " \n",
      "LABEL IS neutral\n",
      "[('про те що', 30), ('після того як', 20), ('президент володимир зеленський', 19), ('це означає що', 14), ('ðºð¾ð¼ð ð¾ð ð¾ñ', 14), ('тисяч років тому', 13), ('на той час', 12), ('очікувана тривалість життя', 12), ('через те що', 10), ('на близькому сході', 9), ('про це йдеться', 9), ('першого заступника голови', 9), ('на позачерговому засіданні', 9), ('ми говоримо про', 8), ('на відміну від', 8), ('до того як', 8), ('ð½ñ ðµñ ðµñ', 8), ('ð¼ð ð¹ð ðµ', 8), ('ð¾ð ð¾ñ ð¾ð', 8), ('шаджар ад дурр', 8), ('йдеться на сайті', 8), ('ми знаємо що', 7), ('так само як', 7), ('для профілактики грипу', 7), ('не виключено що', 7), ('прем єр міністр', 7), ('фракції європейська солідарність', 7), ('всіх на всіх', 7), ('це може бути', 6), ('для того щоб', 6), ('людей біполярним розладом', 6), ('ð½ð ð²ñ ð²', 6), ('ð¹ð ðµ ð½ðµ', 6), ('ð¾ ð¾ñ ð¾', 6), ('ð¹ ð³ð½ñ ð²ñ', 6), ('ð³ð½ñ ð²ñ ðµñ', 6), ('ð²ñ ðµñ ðµ', 6), ('ðµñ ðµ ð¾ð', 6), ('ðµ ð¾ð ð¾ñ', 6), ('ð¾ñ ð¾ð ðµ', 6)]\n",
      " \n",
      "================================================================================\n",
      " NGRAM = 2\n",
      "LABEL IS subjective\n",
      "[('propn propn', 480), ('propn та', 104), ('те що', 83), ('тому що', 58), ('та propn', 53), ('під час', 51), ('це не', 51), ('propn на', 45), ('може бути', 42), ('на propn', 42), ('propn не', 40), ('не може', 39), ('2019 року', 34), ('не лише', 32), ('не буде', 31), ('propn це', 31), ('так само', 30), ('про те', 30), ('власників землі', 30), ('що propn', 29), ('того що', 27), ('до propn', 27), ('propn про', 27), ('до того', 26), ('propn який', 26), ('відповідно до', 25), ('млрд грн', 25), ('не тільки', 25), ('не було', 24), ('того щоб', 24), ('не має', 23), ('чи не', 22), ('що не', 22), ('2020 року', 21), ('тому числі', 21), ('як propn', 21), ('тих хто', 21), ('таким чином', 20), ('навіть якщо', 20), ('але не', 20)]\n",
      " \n",
      "LABEL IS neutral\n",
      "[('propn propn', 1093), ('під час', 135), ('propn та', 101), ('те що', 85), ('до propn', 84), ('propn на', 82), ('про це', 79), ('тому що', 76), ('на propn', 66), ('та propn', 59), ('що propn', 49), ('propn не', 49), ('propn який', 46), ('про те', 42), ('propn за', 40), ('не було', 36), ('ð½ð ð¾ð', 36), ('прим ред', 34), ('що це', 32), ('ð¾ð ð¾ñ', 32), ('крім того', 31), ('до того', 31), ('того як', 31), ('2019 року', 30), ('ðµñ ðµð', 30), ('ð¾ð ð½ð', 30), ('тривалість життя', 29), ('propn був', 29), ('року propn', 28), ('президент propn', 28), ('на території', 27), ('propn він', 26), ('років тому', 26), ('але не', 26), ('за допомогою', 26), ('propn про', 25), ('на початку', 25), ('не лише', 25), ('propn це', 25), ('не тільки', 25)]\n",
      " \n",
      " NGRAM = 3\n",
      "LABEL IS subjective\n",
      "[('propn propn propn', 105), ('propn та propn', 47), ('propn propn та', 22), ('про те що', 20), ('закону propn про', 15), ('та propn propn', 13), ('внесення змін до', 13), ('не може бути', 11), ('так само як', 10), ('той же час', 10), ('для того щоб', 10), ('про внесення змін', 10), ('після того як', 9), ('propn propn який', 9), ('замість того щоб', 9), ('верховної ради propn', 9), ('на відміну від', 8), ('той факт що', 8), ('на те що', 8), ('кримінального кодексу propn', 8), ('propn чи propn', 7), ('propn propn це', 7), ('за словами propn', 7), ('президент propn propn', 7), ('propn на propn', 7), ('ринку електричної енергії', 7), ('товариства власників землі', 7), ('на тимчасово окупованій', 7), ('тимчасово окупованій території', 7), ('якщо припустити що', 6), ('через те що', 6), ('але це не', 6), ('це не означає', 6), ('переклав propn propn', 6), ('завдання для волонтерів', 6), ('propn propn не', 6), ('propn propn на', 6), ('президента propn propn', 6), ('другої світової війни', 6), ('як propn propn', 6)]\n",
      " \n",
      "LABEL IS neutral\n",
      "[('propn propn propn', 248), ('propn та propn', 45), ('про те що', 30), ('propn propn який', 29), ('propn propn та', 27), ('propn propn на', 26), ('президент propn propn', 24), ('після того як', 20), ('це означає що', 14), ('ðºð¾ð¼ð ð¾ð ð¾ñ', 14), ('тисяч років тому', 13), ('на той час', 12), ('propn propn був', 12), ('очікувана тривалість життя', 12), ('на території propn', 11), ('через те що', 10), ('та propn propn', 10), ('що propn propn', 10), ('propn на propn', 10), ('президента propn propn', 10), ('propn propn за', 9), ('на близькому сході', 9), ('про це йдеться', 9), ('першого заступника голови', 9), ('міністр propn propn', 9), ('на позачерговому засіданні', 9), ('propn propn він', 8), ('ми говоримо про', 8), ('на відміну від', 8), ('до того як', 8), ('ð½ñ ðµñ ðµñ', 8), ('ð²ñ ð½ ð½ð', 8), ('ð¾ð ð¾ñ ð¾ð', 8), ('ðµñ ð¾ð ð¾ñ', 8), ('propn вважає що', 8), ('до propn propn', 8), ('йдеться на сайті', 8), ('propn propn заявив', 8), ('верховної ради propn', 8), ('ради propn propn', 8)]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None, ngrams=2):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    get_top_n_words([\"I love Python\", \"Python is a language programming\", \"Hello world\", \"I love the world\"]) -> \n",
    "    [('python', 2),\n",
    "     ('world', 2),\n",
    "     ('love', 2),\n",
    "     ('hello', 1),\n",
    "     ('is', 1),\n",
    "     ('programming', 1),\n",
    "     ('the', 1),\n",
    "     ('language', 1)]\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(\n",
    "        ngram_range=(ngrams,ngrams),\n",
    "    ).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ngram in (2,3):\n",
    "    print(f' NGRAM = {ngram}')\n",
    "    for label in ('subjective', 'neutral'):\n",
    "        print(f'LABEL IS {label}')\n",
    "        label_revs = df[df['label']==label]['text'].values\n",
    "        print(get_top_n_words(label_revs, 40, ngrams=ngram))\n",
    "        print(' ')\n",
    "        \n",
    "print('='*80)\n",
    "        \n",
    "for ngram in (2,3):\n",
    "    print(f' NGRAM = {ngram}')\n",
    "    for label in ('subjective', 'neutral'):\n",
    "        print(f'LABEL IS {label}')\n",
    "        label_revs = df[df['label']==label]['text_without_propn'].values\n",
    "        print(get_top_n_words(label_revs, 40, ngrams=ngram))\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
